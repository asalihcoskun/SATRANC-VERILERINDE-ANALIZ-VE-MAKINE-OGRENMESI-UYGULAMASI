{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3169e5ae-9c3b-45fb-ac2d-6ec69878a8d2",
   "metadata": {},
   "source": [
    "# MODEL YARATMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeeb141b-b213-47c6-88ed-468a5636ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate, KFold, GroupKFold, StratifiedGroupKFold, ShuffleSplit, StratifiedShuffleSplit\n",
    "import sklearn.datasets as skds\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb087ed-1651-4fc5-a093-296ac03bbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "carlsen=pd.read_parquet(\"Carlsen V2.parquet\")\n",
    "nakamura=pd.read_parquet(\"Nakamura V2.parquet\")\n",
    "caruana=pd.read_parquet(\"Caruana V2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a131d142-e21d-4a77-8918-572a73f10ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"ECO\",\"Game Class\", \"Phase\", \"Game Length\", \"Best Move Rate Classify\", \"Game Ending Reason\"]\n",
    "for column in categorical_columns:\n",
    "    carlsen[column] = carlsen[column].astype(\"category\")\n",
    "    nakamura[column] = nakamura[column].astype(\"category\")\n",
    "    caruana[column] = caruana[column].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ccad7d2-9f50-4774-a541-11cbed7be372",
   "metadata": {},
   "outputs": [],
   "source": [
    "carlsen['Player'] = 0   #'Carlsen'\n",
    "nakamura['Player'] = 1  #'Nakamura'\n",
    "caruana['Player'] = 2   #'Caruana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb867abf-23ce-4e27-a5d3-675e9adeb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullanılacak olan sütunlar\n",
    "selected_columns = [\"ECO\",\"Game Class\", \"Phase\", \"Game Length\", \"Best Move Rate Classify\", \"Game Ending Reason\", \"Player\"]\n",
    "\n",
    "carlsen_df_selected = carlsen[selected_columns]\n",
    "nakamura_df_selected = nakamura[selected_columns]\n",
    "caruana_df_selected = caruana[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d8f4944-cb1f-4d59-9307-4f0b30e02b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "carlsen_df_balanced = carlsen_df_selected.sample(n=min(4500, len(carlsen_df_selected)))\n",
    "nakamura_df_balanced = nakamura_df_selected.sample(n=min(4500, len(nakamura_df_selected)))\n",
    "caruana_df_balanced = caruana_df_selected.sample(n=min(4500, len(caruana_df_selected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24503d4b-48cb-4097-a605-ecf4d4ab9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players_df_selected = pd.concat([carlsen_df_balanced, nakamura_df_balanced, caruana_df_balanced])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8a15eed-d647-46f6-a80d-680ffa61c3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding işlemi\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "ohe.fit(all_players_df_selected[[\"ECO\",\"Game Class\", \"Phase\", \"Game Length\", \"Best Move Rate Classify\", \"Game Ending Reason\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1136038-0f82-43ca-b632-2a93a75983f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = pd.DataFrame(ohe.transform(all_players_df_selected[[\"ECO\",\"Game Class\", \"Phase\", \"Game Length\", \"Best Move Rate Classify\", \"Game Ending Reason\"]]),\n",
    "                              columns = list(ohe.get_feature_names()))\n",
    "y = all_players_df_selected[\"Player\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2d6f26c-9d3d-4527-8e41-acc88570596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a6aedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000, multi_class='auto',solver= \"newton-cg\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6bab075-fd79-43a7-9370-093d9e9a3f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Doğruluğu: 0.5207407407407407\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Doğruluğu:\", accuracy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14df205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.50       900\n",
      "           1       0.54      0.55      0.54       900\n",
      "           2       0.50      0.54      0.52       900\n",
      "\n",
      "    accuracy                           0.52      2700\n",
      "   macro avg       0.52      0.52      0.52      2700\n",
      "weighted avg       0.52      0.52      0.52      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07ca0d8e-b6d2-4415-9986-699d2f04590e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cm, \n",
    "            annot=True,\n",
    "            fmt='g', \n",
    "            xticklabels=['Carlsen','Nakamura','Caruana'],\n",
    "            yticklabels=['Carlsen','Nakamura','Caruana']\n",
    "           )\n",
    "plt.xlabel('Prediction',fontsize=13)\n",
    "plt.ylabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5f721f3-3356-47e9-9b98-79c9ed707bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import t\n",
    "\n",
    "def modeling_with_confidence_intervals(model, X, y, n_iterations=1000, test_size=0.2, random_state=42):\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=random_state+i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "        precision_list.append(precision_score(y_test, y_pred, zero_division=0,average='weighted'))\n",
    "        recall_list.append(recall_score(y_test, y_pred, zero_division=0,average='weighted'))\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'accuracy': accuracy_list,\n",
    "        'precision': precision_list,\n",
    "        'recall': recall_list\n",
    "    })\n",
    "\n",
    "    mean_metrics = metrics_df.mean()\n",
    "    sem_metrics = metrics_df.sem()\n",
    "    \n",
    "    confidence_intervals = {}\n",
    "    confidence_level = 0.95\n",
    "    degrees_freedom = n_iterations - 1\n",
    "    t_critical = t.ppf((1 + confidence_level) / 2, degrees_freedom)\n",
    "    \n",
    "    for metric in mean_metrics.index:\n",
    "        ci_margin = sem_metrics[metric] * t_critical\n",
    "        confidence_intervals[metric] = (mean_metrics[metric] - ci_margin, mean_metrics[metric] + ci_margin)\n",
    "\n",
    "    return metrics_df, confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95883af7-95d0-493e-a7a2-1ada653901d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    accuracy  precision    recall\n",
       " 0   0.492963   0.493085  0.492963\n",
       " 1   0.501111   0.502321  0.501111\n",
       " 2   0.503704   0.504591  0.503704\n",
       " 3   0.506296   0.507037  0.506296\n",
       " 4   0.498519   0.499136  0.498519\n",
       " 5   0.498519   0.498476  0.498519\n",
       " 6   0.512593   0.513631  0.512593\n",
       " 7   0.507407   0.507540  0.507407\n",
       " 8   0.500370   0.501069  0.500370\n",
       " 9   0.486296   0.487120  0.486296\n",
       " 10  0.504074   0.503819  0.504074\n",
       " 11  0.507037   0.508700  0.507037\n",
       " 12  0.509630   0.511216  0.509630\n",
       " 13  0.500741   0.500551  0.500741\n",
       " 14  0.502222   0.502877  0.502222\n",
       " 15  0.483333   0.484392  0.483333\n",
       " 16  0.501852   0.502475  0.501852\n",
       " 17  0.486296   0.486265  0.486296\n",
       " 18  0.504074   0.505191  0.504074\n",
       " 19  0.506667   0.507428  0.506667\n",
       " 20  0.484815   0.485895  0.484815\n",
       " 21  0.508148   0.509727  0.508148\n",
       " 22  0.495556   0.495469  0.495556\n",
       " 23  0.517407   0.517578  0.517407\n",
       " 24  0.508148   0.508826  0.508148\n",
       " 25  0.507778   0.508810  0.507778\n",
       " 26  0.502963   0.505115  0.502963\n",
       " 27  0.487407   0.487573  0.487407\n",
       " 28  0.509259   0.509553  0.509259\n",
       " 29  0.512963   0.513078  0.512963,\n",
       " {'accuracy': (0.49828332282255927, 0.5049265537206505),\n",
       "  'precision': (0.49892572863037404, 0.5056436064560281),\n",
       "  'recall': (0.49828332282255927, 0.5049265537206505)})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_with_confidence_intervals(model, X_encoded, y, n_iterations=30, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc160fb",
   "metadata": {},
   "source": [
    "# SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "201cc20f-ff7d-4cdd-bab4-c849192546ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf',random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c8e0561-ff7f-46fd-950b-9e62ca5e17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Doğruluğu: 0.515375854214123\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Model Doğruluğu:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb401c",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b652e33-958d-4a05-ba91-974b65104206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3779a86d-0016-4f92-8319-7878278ce1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Doğruluğu: 0.48604783599088835\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Doğruluğu:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfdba7f2-11b9-4b66-a6dd-85dd5362f283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f_i = list(zip(X_encoded.columns,model.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "f_i = f_i[:30]\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb77fe-6859-4e78-8fe3-3c760c8a3e28",
   "metadata": {},
   "source": [
    "# SUPERVISED CLASSIFICATION MODELS TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ea9214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0_A00', 'x0_A01', 'x0_A02', 'x0_A03', 'x0_A04', 'x0_A05', 'x0_A06',\n",
       "       'x0_A07', 'x0_A08', 'x0_A09',\n",
       "       ...\n",
       "       'x3_medium-length', 'x3_miniature', 'x3_very long', 'x4_iyi', 'x4_kötü',\n",
       "       'x4_orta', 'x4_çok iyi', 'x5_Mate', 'x5_Resign', 'x5_nan'],\n",
       "      dtype='object', length=471)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c33b6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "#    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=10),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "#    'Neural Network': MLPClassifier(max_iter=10000)\n",
    "    'AdaBoost':AdaBoostClassifier(n_estimators=10),\n",
    "    'XGBoost': xgb.XGBClassifier(objective='binary:logistic', eval_metric='error'),\n",
    "    'LightGBM':LGBMClassifier(num_leaves=10, n_estimators=50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d78c5e27-e7ac-4175-9a57-85a43b9aad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy': make_scorer(accuracy_score), \n",
    "           'precision': make_scorer(precision_score, average='macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b8988d1-a71e-411d-9ddb-43100a4c6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "302f2d77-0e15-41b7-8724-fb5cd07df9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(X, y, model,strategy,n_folds=3):\n",
    "    results = {}\n",
    "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "    scores = cross_validate(strategy(model), X, y,\n",
    "                            cv=cv,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=False,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "\n",
    "\n",
    "    \n",
    "    results = {\n",
    "#        'Model':model,\n",
    "        'test_accuracy_std': np.std(scores['test_accuracy']),\n",
    "        'test_accuracy_mean': np.mean(scores['test_accuracy']), \n",
    "        'test_accuracy_conf_interval': (np.mean(scores['test_accuracy']) - 1.96 * np.std(scores['test_accuracy']) / np.sqrt(len(scores['test_accuracy'])),\n",
    "                          np.mean(scores['test_accuracy']) + 1.96 * np.std(scores['test_accuracy']) / np.sqrt(len(scores['test_accuracy']))),\n",
    "        'test_precision_std': np.std(scores['test_precision']),\n",
    "        'test_precision_mean': np.mean(scores['test_precision']), \n",
    "        'test_precision_conf_interval': (np.mean(scores['test_precision']) - 1.96 * np.std(scores['test_precision']) / np.sqrt(len(scores['test_precision'])),\n",
    "                          np.mean(scores['test_precision']) + 1.96 * np.std(scores['test_precision']) / np.sqrt(len(scores['test_precision']))),\n",
    "        'test_recall_std': np.std(scores['test_recall']),\n",
    "        'test_recall_mean': np.mean(scores['test_recall']), \n",
    "        'test_recall_conf_interval': (np.mean(scores['test_recall']) - 1.96 * np.std(scores['test_recall']) / np.sqrt(len(scores['test_recall'])),\n",
    "                          np.mean(scores['test_recall']) + 1.96 * np.std(scores['test_recall']) / np.sqrt(len(scores['test_recall']))),\n",
    "        'fit_time': np.sum(scores['fit_time'])\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efbbccec-b549-4931-8bfb-d7aa84945b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.4s remaining:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   34.0s remaining:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   34.0s remaining:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.4s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.9s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.7s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.4min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   48.5s remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   48.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(n_estimators=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.9s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(n_estimators=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.8s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='error', feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.9s remaining:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='error', feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.4s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(n_estimators=50, num_leaves=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.1s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(n_estimators=50, num_leaves=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    for ensemble_type, ensemble_name in [(OneVsRestClassifier, 'One-vs-Rest'), (OneVsOneClassifier, 'One-vs-One')]:\n",
    "        print(model)\n",
    "        model_results = evaluate_model(X_encoded, y, model, ensemble_type,n_folds=5)\n",
    "        result = {\n",
    "            'Model': model_name,\n",
    "            'Ensemble Type': ensemble_name,\n",
    "            'Accuracy': model_results['test_accuracy_mean'],\n",
    "            'Accuracy CI': model_results['test_accuracy_conf_interval'],\n",
    "            'Precision': model_results['test_precision_mean'],\n",
    "            'Precision CI': model_results['test_precision_conf_interval'],\n",
    "            'Recall': model_results['test_recall_mean'],\n",
    "            'Recall CI': model_results['test_recall_conf_interval'],\n",
    "            'Time (s)': model_results['fit_time']\n",
    "        }\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25fed586-67c9-4276-adb0-daa2f2b2f4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Ensemble Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy CI</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Precision CI</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Recall CI</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.517799</td>\n",
       "      <td>(0.5121637400084523, 0.5234344677719761)</td>\n",
       "      <td>0.500729</td>\n",
       "      <td>(0.4943466120317197, 0.507111431993039)</td>\n",
       "      <td>0.484585</td>\n",
       "      <td>(0.4781760195200621, 0.49099352964267035)</td>\n",
       "      <td>34.747620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>(0.5143707727655984, 0.5171266557522587)</td>\n",
       "      <td>0.497871</td>\n",
       "      <td>(0.49415830676057854, 0.5015831234525951)</td>\n",
       "      <td>0.481969</td>\n",
       "      <td>(0.48041863462917916, 0.4835186485263597)</td>\n",
       "      <td>19.226270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.510167</td>\n",
       "      <td>(0.5082157578642602, 0.5121182850298914)</td>\n",
       "      <td>0.497986</td>\n",
       "      <td>(0.493542366344154, 0.5024296601195952)</td>\n",
       "      <td>0.466790</td>\n",
       "      <td>(0.46492646977475144, 0.46865350652124044)</td>\n",
       "      <td>36.004910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.508402</td>\n",
       "      <td>(0.5014060578053121, 0.5153975253362495)</td>\n",
       "      <td>0.495096</td>\n",
       "      <td>(0.4876214111323518, 0.5025703241902877)</td>\n",
       "      <td>0.467075</td>\n",
       "      <td>(0.461471017534563, 0.4726780441046575)</td>\n",
       "      <td>19.467831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.501053</td>\n",
       "      <td>(0.49638025207665265, 0.5057265012511573)</td>\n",
       "      <td>0.513931</td>\n",
       "      <td>(0.5072156556788917, 0.520647333347153)</td>\n",
       "      <td>0.445951</td>\n",
       "      <td>(0.44151874170682626, 0.4503826413888574)</td>\n",
       "      <td>13.914259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.498776</td>\n",
       "      <td>(0.49579396509373513, 0.5017571417757262)</td>\n",
       "      <td>0.525886</td>\n",
       "      <td>(0.5185410154484145, 0.533231510014563)</td>\n",
       "      <td>0.439160</td>\n",
       "      <td>(0.4356890497942029, 0.4426304881849759)</td>\n",
       "      <td>422.754933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.498092</td>\n",
       "      <td>(0.49285486226980485, 0.5033288856516318)</td>\n",
       "      <td>0.527965</td>\n",
       "      <td>(0.5187401094318715, 0.5371908151405975)</td>\n",
       "      <td>0.437591</td>\n",
       "      <td>(0.4320585650552928, 0.44312393293424807)</td>\n",
       "      <td>241.251883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.497807</td>\n",
       "      <td>(0.49671158469434984, 0.49890271958461974)</td>\n",
       "      <td>0.502189</td>\n",
       "      <td>(0.49261046274557696, 0.5117668999278169)</td>\n",
       "      <td>0.444720</td>\n",
       "      <td>(0.44323057524212955, 0.44620871269437584)</td>\n",
       "      <td>11.484447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>(0.4763878373480131, 0.4861901716299532)</td>\n",
       "      <td>0.510035</td>\n",
       "      <td>(0.4908607751021356, 0.5292092002356678)</td>\n",
       "      <td>0.424235</td>\n",
       "      <td>(0.4195716609047146, 0.4288991029310751)</td>\n",
       "      <td>17.806505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.479296</td>\n",
       "      <td>(0.4750650836985957, 0.48352633318903826)</td>\n",
       "      <td>0.488234</td>\n",
       "      <td>(0.4694295988565827, 0.50703847485221)</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>(0.4166136927241061, 0.42652450451941704)</td>\n",
       "      <td>5.694531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.477473</td>\n",
       "      <td>(0.4710939007480043, 0.4838519284682111)</td>\n",
       "      <td>0.506689</td>\n",
       "      <td>(0.488991488899849, 0.5243862366608298)</td>\n",
       "      <td>0.419223</td>\n",
       "      <td>(0.41284947655290877, 0.4255963320520953)</td>\n",
       "      <td>12.073919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.475081</td>\n",
       "      <td>(0.4740322388078613, 0.4761302183962788)</td>\n",
       "      <td>0.483324</td>\n",
       "      <td>(0.46810617223823237, 0.49854196227066194)</td>\n",
       "      <td>0.412435</td>\n",
       "      <td>(0.41066554866764626, 0.41420541915908893)</td>\n",
       "      <td>10.531042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.473999</td>\n",
       "      <td>(0.46955278709652143, 0.47844452561218637)</td>\n",
       "      <td>0.453492</td>\n",
       "      <td>(0.44858453915750707, 0.458399385678833)</td>\n",
       "      <td>0.449139</td>\n",
       "      <td>(0.44519093589829495, 0.45308640121560007)</td>\n",
       "      <td>12.856661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.471949</td>\n",
       "      <td>(0.4669472352420127, 0.4769509850600772)</td>\n",
       "      <td>0.450330</td>\n",
       "      <td>(0.4442709373365, 0.4563890625156063)</td>\n",
       "      <td>0.446415</td>\n",
       "      <td>(0.44126803863542263, 0.4515613791455748)</td>\n",
       "      <td>7.429910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.397277</td>\n",
       "      <td>(0.38355494866893014, 0.41099984787353416)</td>\n",
       "      <td>0.412410</td>\n",
       "      <td>(0.3992092703023347, 0.42561169931431947)</td>\n",
       "      <td>0.401494</td>\n",
       "      <td>(0.3946710530060635, 0.4083171469286255)</td>\n",
       "      <td>88.243607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.378025</td>\n",
       "      <td>(0.3664661156880005, 0.3895829497613617)</td>\n",
       "      <td>0.378612</td>\n",
       "      <td>(0.36266889432059435, 0.3945548254825957)</td>\n",
       "      <td>0.374161</td>\n",
       "      <td>(0.36208898323733374, 0.38623346342852094)</td>\n",
       "      <td>133.809689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.312810</td>\n",
       "      <td>(0.30916923258854573, 0.3164500868429319)</td>\n",
       "      <td>0.466129</td>\n",
       "      <td>(0.4494557103218859, 0.48280324335330416)</td>\n",
       "      <td>0.372708</td>\n",
       "      <td>(0.3693411853481623, 0.3760751426702108)</td>\n",
       "      <td>2.541618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.287179</td>\n",
       "      <td>(0.2862313617745708, 0.288126611117654)</td>\n",
       "      <td>0.456261</td>\n",
       "      <td>(0.44384659390860093, 0.46867476500286553)</td>\n",
       "      <td>0.352119</td>\n",
       "      <td>(0.3514434861164225, 0.3527936481198737)</td>\n",
       "      <td>2.623697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Ensemble Type  Accuracy  \\\n",
       "0      Logistic Regression   One-vs-Rest  0.517799   \n",
       "1      Logistic Regression    One-vs-One  0.515749   \n",
       "14                 XGBoost   One-vs-Rest  0.510167   \n",
       "15                 XGBoost    One-vs-One  0.508402   \n",
       "16                LightGBM   One-vs-Rest  0.501053   \n",
       "8        Gradient Boosting   One-vs-Rest  0.498776   \n",
       "9        Gradient Boosting    One-vs-One  0.498092   \n",
       "17                LightGBM    One-vs-One  0.497807   \n",
       "12                AdaBoost   One-vs-Rest  0.481289   \n",
       "5            Decision Tree    One-vs-One  0.479296   \n",
       "13                AdaBoost    One-vs-One  0.477473   \n",
       "4            Decision Tree   One-vs-Rest  0.475081   \n",
       "6            Random Forest   One-vs-Rest  0.473999   \n",
       "7            Random Forest    One-vs-One  0.471949   \n",
       "3   Support Vector Machine    One-vs-One  0.397277   \n",
       "2   Support Vector Machine   One-vs-Rest  0.378025   \n",
       "11             Naive Bayes    One-vs-One  0.312810   \n",
       "10             Naive Bayes   One-vs-Rest  0.287179   \n",
       "\n",
       "                                   Accuracy CI  Precision  \\\n",
       "0     (0.5121637400084523, 0.5234344677719761)   0.500729   \n",
       "1     (0.5143707727655984, 0.5171266557522587)   0.497871   \n",
       "14    (0.5082157578642602, 0.5121182850298914)   0.497986   \n",
       "15    (0.5014060578053121, 0.5153975253362495)   0.495096   \n",
       "16   (0.49638025207665265, 0.5057265012511573)   0.513931   \n",
       "8    (0.49579396509373513, 0.5017571417757262)   0.525886   \n",
       "9    (0.49285486226980485, 0.5033288856516318)   0.527965   \n",
       "17  (0.49671158469434984, 0.49890271958461974)   0.502189   \n",
       "12    (0.4763878373480131, 0.4861901716299532)   0.510035   \n",
       "5    (0.4750650836985957, 0.48352633318903826)   0.488234   \n",
       "13    (0.4710939007480043, 0.4838519284682111)   0.506689   \n",
       "4     (0.4740322388078613, 0.4761302183962788)   0.483324   \n",
       "6   (0.46955278709652143, 0.47844452561218637)   0.453492   \n",
       "7     (0.4669472352420127, 0.4769509850600772)   0.450330   \n",
       "3   (0.38355494866893014, 0.41099984787353416)   0.412410   \n",
       "2     (0.3664661156880005, 0.3895829497613617)   0.378612   \n",
       "11   (0.30916923258854573, 0.3164500868429319)   0.466129   \n",
       "10     (0.2862313617745708, 0.288126611117654)   0.456261   \n",
       "\n",
       "                                  Precision CI    Recall  \\\n",
       "0      (0.4943466120317197, 0.507111431993039)  0.484585   \n",
       "1    (0.49415830676057854, 0.5015831234525951)  0.481969   \n",
       "14     (0.493542366344154, 0.5024296601195952)  0.466790   \n",
       "15    (0.4876214111323518, 0.5025703241902877)  0.467075   \n",
       "16     (0.5072156556788917, 0.520647333347153)  0.445951   \n",
       "8      (0.5185410154484145, 0.533231510014563)  0.439160   \n",
       "9     (0.5187401094318715, 0.5371908151405975)  0.437591   \n",
       "17   (0.49261046274557696, 0.5117668999278169)  0.444720   \n",
       "12    (0.4908607751021356, 0.5292092002356678)  0.424235   \n",
       "5       (0.4694295988565827, 0.50703847485221)  0.421569   \n",
       "13     (0.488991488899849, 0.5243862366608298)  0.419223   \n",
       "4   (0.46810617223823237, 0.49854196227066194)  0.412435   \n",
       "6     (0.44858453915750707, 0.458399385678833)  0.449139   \n",
       "7        (0.4442709373365, 0.4563890625156063)  0.446415   \n",
       "3    (0.3992092703023347, 0.42561169931431947)  0.401494   \n",
       "2    (0.36266889432059435, 0.3945548254825957)  0.374161   \n",
       "11   (0.4494557103218859, 0.48280324335330416)  0.372708   \n",
       "10  (0.44384659390860093, 0.46867476500286553)  0.352119   \n",
       "\n",
       "                                     Recall CI    Time (s)  \n",
       "0    (0.4781760195200621, 0.49099352964267035)   34.747620  \n",
       "1    (0.48041863462917916, 0.4835186485263597)   19.226270  \n",
       "14  (0.46492646977475144, 0.46865350652124044)   36.004910  \n",
       "15     (0.461471017534563, 0.4726780441046575)   19.467831  \n",
       "16   (0.44151874170682626, 0.4503826413888574)   13.914259  \n",
       "8     (0.4356890497942029, 0.4426304881849759)  422.754933  \n",
       "9    (0.4320585650552928, 0.44312393293424807)  241.251883  \n",
       "17  (0.44323057524212955, 0.44620871269437584)   11.484447  \n",
       "12    (0.4195716609047146, 0.4288991029310751)   17.806505  \n",
       "5    (0.4166136927241061, 0.42652450451941704)    5.694531  \n",
       "13   (0.41284947655290877, 0.4255963320520953)   12.073919  \n",
       "4   (0.41066554866764626, 0.41420541915908893)   10.531042  \n",
       "6   (0.44519093589829495, 0.45308640121560007)   12.856661  \n",
       "7    (0.44126803863542263, 0.4515613791455748)    7.429910  \n",
       "3     (0.3946710530060635, 0.4083171469286255)   88.243607  \n",
       "2   (0.36208898323733374, 0.38623346342852094)  133.809689  \n",
       "11    (0.3693411853481623, 0.3760751426702108)    2.541618  \n",
       "10    (0.3514434861164225, 0.3527936481198737)    2.623697  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).sort_values(by=['Accuracy','Time (s)'],ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aae98b-ae5c-489d-b6a0-95943c26ef24",
   "metadata": {},
   "source": [
    "# TUNED HYPERPARAMETER ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba5cf99e-b0d8-43dc-b13e-3e8bf80cc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a45b3e4d-0999-4109-bc14-5bd79d344aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(max_iter=1000, multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            'penalty': [None, 'l1', 'l2', 'elasticnet']\n",
    "        }\n",
    "    },\n",
    "    'Support Vector Machine': {\n",
    "        'model': SVC(max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {\n",
    "            'var_smoothing': np.logspace(-9, 0, 10)\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'learning_rate': [0.01, 0.1, 1]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(objective='binary:logistic', eval_metric='error'),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'num_leaves': [10, 20, 31],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdfbbb90-e08e-4855-8e25-2a15efdc961e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Logistic Regression\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "325 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan 0.46528467        nan 0.46653763 0.48954848 0.48960543\n",
      " 0.48499201 0.48954848 0.48954848        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.48989048        nan 0.49450396\n",
      " 0.51113596 0.51113594 0.50834499 0.51113596 0.51113596        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.51301588\n",
      "        nan 0.51404115 0.51649014 0.51649012 0.51466755 0.51649014\n",
      " 0.51649014        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.51495239        nan 0.51626231 0.5159206  0.51597756\n",
      " 0.51500932 0.50219278 0.5159206         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.51518016        nan 0.51574975\n",
      " 0.51586365 0.51574974 0.51512323 0.49535797 0.51586365        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Running GridSearchCV for Support Vector Machine\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Support Vector Machine: {'C': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "\n",
      "Running GridSearchCV for Decision Tree\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for Decision Tree: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\n",
      "Running GridSearchCV for Random Forest\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "Running GridSearchCV for Naive Bayes\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters for Naive Bayes: {'var_smoothing': 0.1}\n",
      "\n",
      "Running GridSearchCV for AdaBoost\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters for AdaBoost: {'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running GridSearchCV for XGBoost\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters for XGBoost: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}\n",
      "\n",
      "Running GridSearchCV for LightGBM\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 392\n",
      "[LightGBM] [Info] Number of data points in the train set: 17557, number of used features: 196\n",
      "[LightGBM] [Info] Start training from score -1.131676\n",
      "[LightGBM] [Info] Start training from score -0.876620\n",
      "[LightGBM] [Info] Start training from score -1.342009\n",
      "Best parameters for LightGBM: {'learning_rate': 0.1, 'n_estimators': 100, 'num_leaves': 20}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over models and perform hyperparameter tuning\n",
    "best_estimators = {}\n",
    "for name, model_info in models.items():\n",
    "    print(f\"Running GridSearchCV for {name}\")\n",
    "    grid_search = GridSearchCV(model_info['model'], model_info['params'], cv=cv, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_encoded, y)\n",
    "    best_estimators[name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2d3306b-c1a2-4c18-bd57-f77ef53bb1de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.4s remaining:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.9s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Machine with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   39.1s remaining:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   39.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Machine with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   33.3s remaining:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   33.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.4s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   21.0s remaining:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   10.6s remaining:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Naive Bayes with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.6s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Naive Bayes with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.7s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AdaBoost with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   34.2s remaining:   51.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AdaBoost with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   21.9s remaining:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py\", line 337, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py\", line 85, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 0 for Parameter num_class should be greater equal to 1\n",
      "num_class: Number of output class in the multi-class classification.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py\", line 742, in fit\n",
      "    Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py\", line 605, in _fit_ovo_binary\n",
      "    _fit_binary(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py\", line 85, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/ahmetsalihcoskun/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 0 for Parameter num_class should be greater equal to 1\n",
      "num_class: Number of output class in the multi-class classification.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LightGBM with One-vs-Rest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.4s remaining:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LightGBM with One-vs-One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.5s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.9s finished\n"
     ]
    }
   ],
   "source": [
    "best_estimators_results = []\n",
    "\n",
    "for model_name, model in best_estimators.items():\n",
    "    for ensemble_type, ensemble_name in [(OneVsRestClassifier, 'One-vs-Rest'), (OneVsOneClassifier, 'One-vs-One')]:\n",
    "        print(f\"Evaluating {model_name} with {ensemble_name}\")\n",
    "        model_results = evaluate_model(X_encoded, y, model, ensemble_type, n_folds=5)\n",
    "        result = {\n",
    "            'Model': model_name,\n",
    "            'Ensemble Type': ensemble_name,\n",
    "            'Accuracy': model_results['test_accuracy_mean'],\n",
    "            'Accuracy CI': model_results['test_accuracy_conf_interval'],\n",
    "            'Precision': model_results['test_precision_mean'],\n",
    "            'Precision CI': model_results['test_precision_conf_interval'],\n",
    "            'Recall': model_results['test_recall_mean'],\n",
    "            'Recall CI': model_results['test_recall_conf_interval'],\n",
    "            'Time (s)': model_results['fit_time']\n",
    "        }\n",
    "        best_estimators_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "248bcd48-7646-42ef-b263-e745f1a4f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_models = pd.DataFrame(best_estimators_results).sort_values(by=['Accuracy','Time (s)'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97d9dad1-3810-4b1d-9011-41455fc09ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Ensemble Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy CI</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Precision CI</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Recall CI</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.517173</td>\n",
       "      <td>(0.5106792298467477, 0.5236659034765077)</td>\n",
       "      <td>0.501049</td>\n",
       "      <td>(0.4931141399094829, 0.508983121491773)</td>\n",
       "      <td>0.484008</td>\n",
       "      <td>(0.47817087189494445, 0.48984448136907977)</td>\n",
       "      <td>46.131741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.514952</td>\n",
       "      <td>(0.5063278146949802, 0.5235754700677148)</td>\n",
       "      <td>0.498402</td>\n",
       "      <td>(0.48847124205548764, 0.508332379371546)</td>\n",
       "      <td>0.481764</td>\n",
       "      <td>(0.4729268278133191, 0.49060185576731763)</td>\n",
       "      <td>28.433942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.511022</td>\n",
       "      <td>(0.5071118457481198, 0.5149312741827969)</td>\n",
       "      <td>0.500195</td>\n",
       "      <td>(0.4965074187932247, 0.5038834767567041)</td>\n",
       "      <td>0.468757</td>\n",
       "      <td>(0.4655256920083301, 0.47198838545201377)</td>\n",
       "      <td>165.790295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.507205</td>\n",
       "      <td>(0.5045136188661454, 0.5098961859192055)</td>\n",
       "      <td>0.498076</td>\n",
       "      <td>(0.4955935069946874, 0.5005588661068109)</td>\n",
       "      <td>0.464871</td>\n",
       "      <td>(0.46200958779201184, 0.46773207197884936)</td>\n",
       "      <td>100.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.505041</td>\n",
       "      <td>(0.5008041343330155, 0.5092777495477133)</td>\n",
       "      <td>0.489915</td>\n",
       "      <td>(0.4845075346668555, 0.49532317362500744)</td>\n",
       "      <td>0.464639</td>\n",
       "      <td>(0.460279894268744, 0.46899815886811774)</td>\n",
       "      <td>2.233285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.504585</td>\n",
       "      <td>(0.5008793047418745, 0.5082911903308844)</td>\n",
       "      <td>0.488823</td>\n",
       "      <td>(0.48434054339440025, 0.4933062785171656)</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>(0.45878244985287814, 0.4685219122272141)</td>\n",
       "      <td>36.899683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.504415</td>\n",
       "      <td>(0.4963021257108847, 0.5125273649429601)</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>(0.4774586631182463, 0.4953907984736495)</td>\n",
       "      <td>0.467930</td>\n",
       "      <td>(0.46109984156614536, 0.47476007911150553)</td>\n",
       "      <td>50.013101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.501852</td>\n",
       "      <td>(0.49325537706401834, 0.5104486666540976)</td>\n",
       "      <td>0.487225</td>\n",
       "      <td>(0.47622276057036916, 0.49822759683213114)</td>\n",
       "      <td>0.459738</td>\n",
       "      <td>(0.4516772972110407, 0.46779905143336925)</td>\n",
       "      <td>36.519529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.501509</td>\n",
       "      <td>(0.4955976774579843, 0.5074212107871602)</td>\n",
       "      <td>0.485845</td>\n",
       "      <td>(0.47826468532477173, 0.4934259254456246)</td>\n",
       "      <td>0.461757</td>\n",
       "      <td>(0.45619979504065195, 0.467314855326964)</td>\n",
       "      <td>2.077031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.498092</td>\n",
       "      <td>(0.4924800534301747, 0.5037042459634006)</td>\n",
       "      <td>0.478317</td>\n",
       "      <td>(0.47114499836851775, 0.48548898126076667)</td>\n",
       "      <td>0.464305</td>\n",
       "      <td>(0.4582690692022861, 0.47034100867697565)</td>\n",
       "      <td>103.202607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.487783</td>\n",
       "      <td>(0.4837894112560304, 0.49177618830123465)</td>\n",
       "      <td>0.477894</td>\n",
       "      <td>(0.46767914841731834, 0.4881085832959828)</td>\n",
       "      <td>0.435766</td>\n",
       "      <td>(0.43322948242721493, 0.43830169311024225)</td>\n",
       "      <td>21.051365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.486757</td>\n",
       "      <td>(0.4783859471373003, 0.4951285653386214)</td>\n",
       "      <td>0.469063</td>\n",
       "      <td>(0.4541215087204572, 0.4840035716769596)</td>\n",
       "      <td>0.436722</td>\n",
       "      <td>(0.427602560874382, 0.4458418769450353)</td>\n",
       "      <td>11.760662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>0.382069</td>\n",
       "      <td>(0.3641972451712523, 0.3999398728613027)</td>\n",
       "      <td>0.384813</td>\n",
       "      <td>(0.37851758847034805, 0.39110895380255467)</td>\n",
       "      <td>0.384939</td>\n",
       "      <td>(0.3809029271142514, 0.38897498077040843)</td>\n",
       "      <td>102.573109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>0.377282</td>\n",
       "      <td>(0.3507516592473247, 0.4038115131837397)</td>\n",
       "      <td>0.366900</td>\n",
       "      <td>(0.3530725141720545, 0.38072774951252625)</td>\n",
       "      <td>0.359620</td>\n",
       "      <td>(0.3529743967089801, 0.3662662535082729)</td>\n",
       "      <td>159.098713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>One-vs-Rest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>5.161424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>One-vs-One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>3.503068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Ensemble Type  Accuracy  \\\n",
       "0      Logistic Regression   One-vs-Rest  0.517173   \n",
       "1      Logistic Regression    One-vs-One  0.514952   \n",
       "10                AdaBoost   One-vs-Rest  0.511022   \n",
       "11                AdaBoost    One-vs-One  0.507205   \n",
       "8              Naive Bayes   One-vs-Rest  0.505041   \n",
       "15                LightGBM    One-vs-One  0.504585   \n",
       "7            Random Forest    One-vs-One  0.504415   \n",
       "14                LightGBM   One-vs-Rest  0.501852   \n",
       "9              Naive Bayes    One-vs-One  0.501509   \n",
       "6            Random Forest   One-vs-Rest  0.498092   \n",
       "4            Decision Tree   One-vs-Rest  0.487783   \n",
       "5            Decision Tree    One-vs-One  0.486757   \n",
       "3   Support Vector Machine    One-vs-One  0.382069   \n",
       "2   Support Vector Machine   One-vs-Rest  0.377282   \n",
       "12                 XGBoost   One-vs-Rest       NaN   \n",
       "13                 XGBoost    One-vs-One       NaN   \n",
       "\n",
       "                                  Accuracy CI  Precision  \\\n",
       "0    (0.5106792298467477, 0.5236659034765077)   0.501049   \n",
       "1    (0.5063278146949802, 0.5235754700677148)   0.498402   \n",
       "10   (0.5071118457481198, 0.5149312741827969)   0.500195   \n",
       "11   (0.5045136188661454, 0.5098961859192055)   0.498076   \n",
       "8    (0.5008041343330155, 0.5092777495477133)   0.489915   \n",
       "15   (0.5008793047418745, 0.5082911903308844)   0.488823   \n",
       "7    (0.4963021257108847, 0.5125273649429601)   0.486425   \n",
       "14  (0.49325537706401834, 0.5104486666540976)   0.487225   \n",
       "9    (0.4955976774579843, 0.5074212107871602)   0.485845   \n",
       "6    (0.4924800534301747, 0.5037042459634006)   0.478317   \n",
       "4   (0.4837894112560304, 0.49177618830123465)   0.477894   \n",
       "5    (0.4783859471373003, 0.4951285653386214)   0.469063   \n",
       "3    (0.3641972451712523, 0.3999398728613027)   0.384813   \n",
       "2    (0.3507516592473247, 0.4038115131837397)   0.366900   \n",
       "12                                 (nan, nan)        NaN   \n",
       "13                                 (nan, nan)        NaN   \n",
       "\n",
       "                                  Precision CI    Recall  \\\n",
       "0      (0.4931141399094829, 0.508983121491773)  0.484008   \n",
       "1     (0.48847124205548764, 0.508332379371546)  0.481764   \n",
       "10    (0.4965074187932247, 0.5038834767567041)  0.468757   \n",
       "11    (0.4955935069946874, 0.5005588661068109)  0.464871   \n",
       "8    (0.4845075346668555, 0.49532317362500744)  0.464639   \n",
       "15   (0.48434054339440025, 0.4933062785171656)  0.463652   \n",
       "7     (0.4774586631182463, 0.4953907984736495)  0.467930   \n",
       "14  (0.47622276057036916, 0.49822759683213114)  0.459738   \n",
       "9    (0.47826468532477173, 0.4934259254456246)  0.461757   \n",
       "6   (0.47114499836851775, 0.48548898126076667)  0.464305   \n",
       "4    (0.46767914841731834, 0.4881085832959828)  0.435766   \n",
       "5     (0.4541215087204572, 0.4840035716769596)  0.436722   \n",
       "3   (0.37851758847034805, 0.39110895380255467)  0.384939   \n",
       "2    (0.3530725141720545, 0.38072774951252625)  0.359620   \n",
       "12                                  (nan, nan)       NaN   \n",
       "13                                  (nan, nan)       NaN   \n",
       "\n",
       "                                     Recall CI    Time (s)  \n",
       "0   (0.47817087189494445, 0.48984448136907977)   46.131741  \n",
       "1    (0.4729268278133191, 0.49060185576731763)   28.433942  \n",
       "10   (0.4655256920083301, 0.47198838545201377)  165.790295  \n",
       "11  (0.46200958779201184, 0.46773207197884936)  100.184770  \n",
       "8     (0.460279894268744, 0.46899815886811774)    2.233285  \n",
       "15   (0.45878244985287814, 0.4685219122272141)   36.899683  \n",
       "7   (0.46109984156614536, 0.47476007911150553)   50.013101  \n",
       "14   (0.4516772972110407, 0.46779905143336925)   36.519529  \n",
       "9     (0.45619979504065195, 0.467314855326964)    2.077031  \n",
       "6    (0.4582690692022861, 0.47034100867697565)  103.202607  \n",
       "4   (0.43322948242721493, 0.43830169311024225)   21.051365  \n",
       "5      (0.427602560874382, 0.4458418769450353)   11.760662  \n",
       "3    (0.3809029271142514, 0.38897498077040843)  102.573109  \n",
       "2     (0.3529743967089801, 0.3662662535082729)  159.098713  \n",
       "12                                  (nan, nan)    5.161424  \n",
       "13                                  (nan, nan)    3.503068  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 272\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563470 -> initscore=0.255257\n",
      "[LightGBM] [Info] Start training from score 0.255257\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 256\n",
      "[LightGBM] [Info] Number of data points in the train set: 8199, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447616 -> initscore=-0.210310\n",
      "[LightGBM] [Info] Start training from score -0.210310\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 5846\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 272\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385666 -> initscore=-0.465566\n",
      "[LightGBM] [Info] Start training from score -0.465566\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4530, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322512 -> initscore=-0.742253\n",
      "[LightGBM] [Info] Start training from score -0.742253\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 8200\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416204 -> initscore=-0.338376\n",
      "[LightGBM] [Info] Start training from score -0.338376\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 10376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261284 -> initscore=-1.039304\n",
      "[LightGBM] [Info] Start training from score -1.039304\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4530, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322512 -> initscore=-0.742253\n",
      "[LightGBM] [Info] Start training from score -0.742253\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 8201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416133 -> initscore=-0.338670\n",
      "[LightGBM] [Info] Start training from score -0.338670\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261356 -> initscore=-1.038935\n",
      "[LightGBM] [Info] Start training from score -1.038935\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 278\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 139\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563373 -> initscore=0.254865\n",
      "[LightGBM] [Info] Start training from score 0.254865\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 262\n",
      "[LightGBM] [Info] Number of data points in the train set: 8201, number of used features: 131\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447628 -> initscore=-0.210258\n",
      "[LightGBM] [Info] Start training from score -0.210258\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 5845\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 135\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385771 -> initscore=-0.465122\n",
      "[LightGBM] [Info] Start training from score -0.465122\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4529, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322464 -> initscore=-0.742473\n",
      "[LightGBM] [Info] Start training from score -0.742473\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 8199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416234 -> initscore=-0.338255\n",
      "[LightGBM] [Info] Start training from score -0.338255\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261303 -> initscore=-1.039207\n",
      "[LightGBM] [Info] Start training from score -1.039207\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4530, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322512 -> initscore=-0.742253\n",
      "[LightGBM] [Info] Start training from score -0.742253\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 8201\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416133 -> initscore=-0.338670\n",
      "[LightGBM] [Info] Start training from score -0.338670\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261356 -> initscore=-1.038935\n",
      "[LightGBM] [Info] Start training from score -1.038935\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4529, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322464 -> initscore=-0.742473\n",
      "[LightGBM] [Info] Start training from score -0.742473\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 8199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416234 -> initscore=-0.338255\n",
      "[LightGBM] [Info] Start training from score -0.338255\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261303 -> initscore=-1.039207\n",
      "[LightGBM] [Info] Start training from score -1.039207\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 280\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563373 -> initscore=0.254865\n",
      "[LightGBM] [Info] Start training from score 0.254865\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 248\n",
      "[LightGBM] [Info] Number of data points in the train set: 8201, number of used features: 124\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447628 -> initscore=-0.210258\n",
      "[LightGBM] [Info] Start training from score -0.210258\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 5845\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 268\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385771 -> initscore=-0.465122\n",
      "[LightGBM] [Info] Start training from score -0.465122\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4530, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322512 -> initscore=-0.742253\n",
      "[LightGBM] [Info] Start training from score -0.742253\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 8200\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416204 -> initscore=-0.338376\n",
      "[LightGBM] [Info] Start training from score -0.338376\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 10376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261284 -> initscore=-1.039304\n",
      "[LightGBM] [Info] Start training from score -1.039304\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 274\n",
      "[LightGBM] [Info] Number of data points in the train set: 10376, number of used features: 137\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563416 -> initscore=0.255036\n",
      "[LightGBM] [Info] Start training from score 0.255036\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 244\n",
      "[LightGBM] [Info] Number of data points in the train set: 8200, number of used features: 122\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447561 -> initscore=-0.210530\n",
      "[LightGBM] [Info] Start training from score -0.210530\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 5846\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385666 -> initscore=-0.465566\n",
      "[LightGBM] [Info] Start training from score -0.465566\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 278\n",
      "[LightGBM] [Info] Number of data points in the train set: 10376, number of used features: 139\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563416 -> initscore=0.255036\n",
      "[LightGBM] [Info] Start training from score 0.255036\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 248\n",
      "[LightGBM] [Info] Number of data points in the train set: 8200, number of used features: 124\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447561 -> initscore=-0.210530\n",
      "[LightGBM] [Info] Start training from score -0.210530\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 5846\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 278\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 139\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385666 -> initscore=-0.465566\n",
      "[LightGBM] [Info] Start training from score -0.465566\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4530, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322512 -> initscore=-0.742253\n",
      "[LightGBM] [Info] Start training from score -0.742253\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 8201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416133 -> initscore=-0.338670\n",
      "[LightGBM] [Info] Start training from score -0.338670\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261356 -> initscore=-1.038935\n",
      "[LightGBM] [Info] Start training from score -1.038935\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 276\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 138\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563373 -> initscore=0.254865\n",
      "[LightGBM] [Info] Start training from score 0.254865\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 258\n",
      "[LightGBM] [Info] Number of data points in the train set: 8201, number of used features: 129\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447628 -> initscore=-0.210258\n",
      "[LightGBM] [Info] Start training from score -0.210258\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 5845\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 276\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 138\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385771 -> initscore=-0.465122\n",
      "[LightGBM] [Info] Start training from score -0.465122\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4529, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 174\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322464 -> initscore=-0.742473\n",
      "[LightGBM] [Info] Start training from score -0.742473\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 8199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 174\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416234 -> initscore=-0.338255\n",
      "[LightGBM] [Info] Start training from score -0.338255\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 174\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261303 -> initscore=-1.039207\n",
      "[LightGBM] [Info] Start training from score -1.039207\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 274\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 137\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563373 -> initscore=0.254865\n",
      "[LightGBM] [Info] Start training from score 0.254865\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 4530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 264\n",
      "[LightGBM] [Info] Number of data points in the train set: 8201, number of used features: 132\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447628 -> initscore=-0.210258\n",
      "[LightGBM] [Info] Start training from score -0.210258\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 5845\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 135\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385771 -> initscore=-0.465122\n",
      "[LightGBM] [Info] Start training from score -0.465122\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4530, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322512 -> initscore=-0.742253\n",
      "[LightGBM] [Info] Start training from score -0.742253\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5845, number of negative: 8201\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416133 -> initscore=-0.338670\n",
      "[LightGBM] [Info] Start training from score -0.338670\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3671, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 173\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261356 -> initscore=-1.038935\n",
      "[LightGBM] [Info] Start training from score -1.038935\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 278\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 139\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563470 -> initscore=0.255257\n",
      "[LightGBM] [Info] Start training from score 0.255257\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 254\n",
      "[LightGBM] [Info] Number of data points in the train set: 8199, number of used features: 127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447616 -> initscore=-0.210310\n",
      "[LightGBM] [Info] Start training from score -0.210310\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 5846\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 276\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 138\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385666 -> initscore=-0.465566\n",
      "[LightGBM] [Info] Start training from score -0.465566\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4529, number of negative: 9516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322464 -> initscore=-0.742473\n",
      "[LightGBM] [Info] Start training from score -0.742473\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 8199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416234 -> initscore=-0.338255\n",
      "[LightGBM] [Info] Start training from score -0.338255\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 10375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261303 -> initscore=-1.039207\n",
      "[LightGBM] [Info] Start training from score -1.039207\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 135\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563470 -> initscore=0.255257\n",
      "[LightGBM] [Info] Start training from score 0.255257\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 252\n",
      "[LightGBM] [Info] Number of data points in the train set: 8199, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447616 -> initscore=-0.210310\n",
      "[LightGBM] [Info] Start training from score -0.210310\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 5846\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 268\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385666 -> initscore=-0.465566\n",
      "[LightGBM] [Info] Start training from score -0.465566\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 352\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876580\n",
      "[LightGBM] [Info] Start training from score -1.342146\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 14045, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.131765\n",
      "[LightGBM] [Info] Start training from score -0.876509\n",
      "[LightGBM] [Info] Start training from score -1.342075\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 14046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.131616\n",
      "[LightGBM] [Info] Start training from score -0.876751\n",
      "[LightGBM] [Info] Start training from score -1.341874\n",
      "[LightGBM] [Info] Number of positive: 5846, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 280\n",
      "[LightGBM] [Info] Number of data points in the train set: 10375, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.563470 -> initscore=0.255257\n",
      "[LightGBM] [Info] Start training from score 0.255257\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 4529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 256\n",
      "[LightGBM] [Info] Number of data points in the train set: 8199, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.447616 -> initscore=-0.210310\n",
      "[LightGBM] [Info] Start training from score -0.210310\n",
      "[LightGBM] [Info] Number of positive: 3670, number of negative: 5846\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 9516, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385666 -> initscore=-0.465566\n",
      "[LightGBM] [Info] Start training from score -0.465566\n"
     ]
    }
   ],
   "source": [
    "tuned_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c050bf0-4692-4d6f-b0a8-23f9b0332212",
   "metadata": {},
   "source": [
    "# BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075f719-be12-4a55-af19-35d8e633185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031f58b-a6d8-47f5-92b1-7dc43f164125",
   "metadata": {},
   "source": [
    "# PICKLE CIKTISI ALMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0566b-c563-4a54-9e6e-b56cd49c5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('onehot.pk', 'wb') as fin:\n",
    "    pickle.dump(ohe, fin)\n",
    "\n",
    "with open('model.pk', 'wb') as fin:\n",
    "    pickle.dump(best_model, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecec18e-39be-4a7b-8fee-0be1b96d1549",
   "metadata": {},
   "source": [
    "# ECO KONTROL VERISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "571902e9-e1ad-44cf-b43e-a823a3e0228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6e1a0-e5a0-4026-8d5c-eee51d2009c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.chessgames.com/chessecohelp.html'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fa3c0-9076-47f7-8343-8c58ceb8940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_uci(moves):\n",
    "    try:\n",
    "        board = chess.Board()\n",
    "        uci_moves = []\n",
    "        for move in moves.split():\n",
    "            if move in ['1','2','3','4','5','6','7','8','9','10']:  # Hamle numaralarını atla\n",
    "                continue\n",
    "            uci_move = board.parse_san(move).uci()\n",
    "            board.push_uci(uci_move)\n",
    "            uci_moves.append(uci_move)\n",
    "        return ' '.join(uci_moves)\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f26fe7aa-ac2f-4663-a36a-2f49825a3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    title = soup.title.string\n",
    "    eco_table = soup.find('table')  \n",
    "    rows = eco_table.find_all('tr')[1:]  \n",
    "    eco_codes = []\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        eco_code = cols[0].text.strip()\n",
    "        description = cols[1].text.strip()\n",
    "        if '\\n' in description:\n",
    "            name, moves = description.split('\\n', 1)\n",
    "        else:\n",
    "            name, moves = description, ''\n",
    "        eco_codes.append((eco_code, name, moves))\n",
    "\n",
    "    df = pd.DataFrame(eco_codes, columns=['ECO Code', 'Description', 'Moves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2958639-aac8-4d91-a502-be49b5446ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UCI Moves'] = df['Moves'].apply(convert_to_uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b27eb75-8f38-4027-b215-df8b5cf66456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('ECO.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
